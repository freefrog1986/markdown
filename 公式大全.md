softmax: $$softmax(x) = \frac {e^{x_i}}{\sum _j e^{x_j}}$$


softmax for word2vec:
$$softmax(u_o^Tv_c) = p(o|c) = \hat y_o = \frac {e^{u_o^Tv_c}}{\sum _{w=1}^W e^{u_w^Tv_c}}$$

overall objeective function by negtive sample:
$$J(\theta) = \frac{1}{T}\sum _{t=1}^TJ_t(\theta)$$

negtive sample cost:
$$J_t(\theta) =log \sigma(u_o^Tv_c)+\sum_{i=1}{k}\mathbb{E}_{j~P(w)}[log\sigma(-u_j^Tv_c)]$$

negtive sample derivative
$$\frac {\partial J}{\partial v_c} = (\sigma(u_o^Tv_c)-1)u_o-\sum _{k=1}^K(\sigma (-u_k^Tv_c)-1)u_k$$
$$\frac {\partial J}{\partial u_o} = (\sigma(u_o^Tv_c)-1)v_c$$
$$\frac {\partial J}{\partial u_k} = -(\sigma(-u_k^Tv_c)-1)v_c, for all k = 1,2,\dots,K$$